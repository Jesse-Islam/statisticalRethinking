---
title: "R hmk notebook"
output:
  html_document:
    df_print: paged
---


https://github.com/rmcelreath/statrethinking_winter2019/tree/master/homework

# homework 1

```{r setup}
library(rethinking)
eval_hmk1<-T
eval_hmk2<-T
eval_hmk3<-T
eval_hmk4<-T
```



```{r hmk1GridApprox,eval=eval_hmk1}
# define grid, number of points to use when
# estimating posterior
p_grid <- seq( from=0 , to=1 , length.out=1000 )

# define initial prior at each point
prior <- rep( 1 , 1000 )

# compute likelihood at each value in grid.
# The likelihood of seeing any of those probabilities
likelihood <- dbinom( 8 , size=15 , prob=p_grid )

# compute product of likelihood and prior
# This is the unstandardized posterior for
# each possible parameter
unstd.posterior <- likelihood * prior

# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)

samples<-sample(p_grid,prob=posterior,size=1e4, replace=T)

# plot the grid
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )


```



```{r weirdPriorhmk1,eval=eval_hmk1}



# define grid, number of points to use when
# estimating posterior
p_grid <- seq( from=0 , to=1 , length.out=1000 )

# define initial prior at each point
prior <- c(rep( 0 , 500 ), rep(.5,500))

# compute likelihood at each value in grid.
# The likelihood of seeing any of those probabilities
likelihood <- dbinom( 8 , size=15 , prob=p_grid )

# compute product of likelihood and prior
# This is the unstandardized posterior for
# each possible parameter
unstd.posterior <- likelihood * prior

# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)


# plot the grid
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )

samples2<-sample(p_grid,prob=posterior,size=1e4, replace=T)


```


```{r hmk1jointSamples,eval=eval_hmk1}

dens(samples,xlab='p',xlim=c(0,1),ylim=c(0,6))
dens(samples2,add=T,lty=2)
abline(v=0.7,col='red')

PI(samples,.99)
PI(samples2,.99)
```

```{r hmk1TrialFunctions,eval=eval_hmk1}

f <-function(n){
  pTrue<-0.7
  w<-rbinom(1,size=n,prob=pTrue)
  
  p_grid <- seq( from=0 , to=1 , length.out=1000 )

# define initial prior at each point
  prior <- rep( 1 , 1000 )

# compute likelihood at each value in grid.
# The likelihood of seeing any of those probabilities
likelihood <- dbinom( w , size=n , prob=p_grid )

# compute product of likelihood and prior
# This is the unstandardized posterior for
# each possible parameter
unstd.posterior <- likelihood * prior

# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)

samples<-sample(p_grid,prob=posterior,size=1e4, replace=T)

PI99<-PI(samples,0.99)
as.numeric(PI99[2]-PI99[1])

}


tests<-rep(floor(seq(1,2000,length.out = 50)),each=50)

width<-sapply(tests,f)
plot(tests,width,xlab="sampleSize",ylab="percentile inverval width")
abline(h=0.05,col='red')

```



```{r w2q1, eval=eval_hmk2}

data(Howell1)
d<-Howell1
d2<-d[d$age>18,]
xbar<-mean(d2$weight)
m4.3<-quap(
  alist(
    height~dnorm(mu,sigma),
    mu~a+b*(weight-xbar),
    a~dnorm(178,20),
    b~dlnorm(0,1),
    sigma~dunif(0,50)
  ),data=d2
)
  

dat<-data.frame(individual=c(1,2,3,4),
                weight=c(45,40,65,31))
h_sim<-sim(m4.3,data=dat)
Eh<-apply(h_sim,2,mean)
h_ci<-apply(h_sim,2,PI,prob=0.89)

dat$Eh<-Eh
dat$L89<-h_ci[1,]
dat$U89<-h_ci[2,]
round(dat,1)

```


```{r w2q2, eval=eval_hmk2}

d$log_weight<-log(d$weight)
d2<-d
xbar<-mean(d2$log_weight)
m2<-quap(
  alist(
    height~dnorm(mu,sigma),
    mu~a+b*(log_weight-xbar),
    a~dnorm(172,20),
    b~dlnorm(0,1),
    sigma~dunif(0,50)
  ),data=d2
)


plot(d$weight,d$height,col=col.alpha(rangi2,0.7))
x_seq<-log(1:60)
mu<-sim(m2, data=list(log_weight=x_seq))
mu_mean<-apply(mu,2,mean)
mu_ci<-apply(mu,2,PI,0.99)
lines(exp(x_seq),mu_mean)
shade(mu_ci,exp(x_seq))

```


```{r w2q3, eval=eval_hmk2}


d$weight_s<-(d$weight-mean(d$weight))/sd(d$weight)
d$weight_s2<-d$weight_s^2

m4.5<-quap(
  alist(
    height~dnorm(mu,sigma),
    mu~a+b1*weight_s+b2*weight_s2,
    a~dnorm(178,20),
    b1~dlnorm(0,1),
    b2~dlnorm(0,1),
    sigma~dunif(0,50)
  ),data=d
)

set.seed(45)
prior<-extract.prior(m4.5)
precis(prior)



w_seq<-seq(from=min(d$weight_s),to=max(d$weight_s),length.out = 50)
w2_seq<-w_seq^2
mu<-link(m4.5,post=prior, data=list(weight_s=w_seq, weight_s2=w2_seq))

plot(NULL,xlim=range(w_seq),ylim=c(55,270),
     xlab='weight(sd)',ylab='height')
for(i in 1:50){
  lines(w_seq,mu[i,], col=col.alpha('black',0.5))
}


```



```{r a3q1,eval=eval_hmk3}

data(foxes)

foxes$W<-standardize(foxes$weight)

foxes$A<-standardize(foxes$area)
foxes$G<-standardize(foxes$groupsize)
foxes$aF<-standardize(foxes$avgfood)

m1<- quap(
  alist(
    W ~dnorm(mu,sigma),
    mu <- a+ ba*A,
    a ~ dnorm(0,0.2),
    ba~dnorm(0,0.5),
    sigma ~dexp(1)
  ),
  data=foxes)

precis(m1)


# you don't control for group size, since we want to total relationship between food and weight. even the indirect though groupsize.
m2<- quap(
  alist(
    W ~dnorm(mu,sigma),
    mu <- a+ baf*aF,
    a ~ dnorm(0,0.2),
    baf~dnorm(0,0.5),
    sigma ~dexp(1)
  ),
  data=foxes)

precis(m2)

m3<- quap(
  alist(
    W ~dnorm(mu,sigma),
    mu <- a+bg*G + baf*aF,
    a ~ dnorm(0,0.2),
    baf~dnorm(0,0.5),
    bg~dnorm(0,0.5),
    sigma ~dexp(1)
  ),
  data=foxes)

precis(m3)


```

```{r a4q1,eval=eval_hmk4}




IB <- list()
IB[[1]] <- c( 0.2 , 0.2 , 0.2 , 0.2 , 0.2 )
IB[[2]] <- c( 0.8 , 0.1 , 0.05 , 0.025 , 0.025 )
IB[[3]] <- c( 0.05 , 0.15 , 0.7 , 0.05 , 0.05 )
sapply( IB , function(p){-sum(p*log(p))} )



DKL<-function(p,q){return(sum(p*(log(p)-log(q))))}

Dm <-matrix(NA,3,3)
for(i in 1:3){
  for(j in 1:3){
    Dm[i,j]<-DKL(IB[[j]],IB[[i]])
  }
}
round(Dm,2)


```



```{r a4q2,eval=eval_hmk4}
d <- sim_happiness( seed=1977 , N_years=1000 )
precis(d)
d2 <- d[ d$age>17 , ] # only adults
d2$A <- ( d2$age - 18 ) / ( 65 - 18 )
d2$mid <- d2$married + 1


m6.9 <- quap(
alist(
happiness ~ dnorm( mu , sigma ),
mu <- a[mid] + bA*A,
a[mid] ~ dnorm( 0 , 1 ),
bA ~ dnorm( 0 , 2 ),
sigma ~ dexp(1)
) , data=d2 )

precis(m6.9,depth=2)


m6.10 <- quap(
alist(
happiness ~ dnorm( mu , sigma ),
mu <- a + bA*A,
a ~ dnorm( 0 , 1 ),
bA ~ dnorm( 0 , 2 ),
sigma ~ dexp(1)
) , data=d2 )

precis(m6.10)


compare(m6.9,m6.10)
```


```{r a4q3,eval=eval_hmk4}

data(foxes)

foxes$W<-standardize(foxes$weight)

foxes$A<-standardize(foxes$area)
foxes$G<-standardize(foxes$groupsize)
foxes$aF<-standardize(foxes$avgfood)



m1<- quap(
  alist(
    W ~dnorm(mu,sigma),
    mu <- a+ ba*A+bg*G+baf*aF,
    a ~ dnorm(0,0.2),
    ba~dnorm(0,0.5),
    bg~dnorm(0,0.5),
    baf~dnorm(0,0.5),
    sigma ~dexp(1)
  ),
  data=foxes)

precis(m1)


m2<- quap(
  alist(
    W ~dnorm(mu,sigma),
    mu <- a+bg*G+baf*aF,
    a ~ dnorm(0,0.2),
    bg~dnorm(0,0.5),
    baf~dnorm(0,0.5),
    sigma ~dexp(1)
  ),
  data=foxes)

precis(m2)


m3<- quap(
  alist(
    W ~dnorm(mu,sigma),
    mu <- a+bg*G+ba*A,
    a ~ dnorm(0,0.2),
    bg~dnorm(0,0.5),
    ba~dnorm(0,0.5),
    sigma ~dexp(1)
  ),
  data=foxes)

precis(m3)


m4<- quap(
  alist(
    W ~dnorm(mu,sigma),
    mu <- a+baf*aF,
    a ~ dnorm(0,0.2),
    baf~dnorm(0,0.5),
    sigma ~dexp(1)
  ),
  data=foxes)

precis(m4)


m5<- quap(
  alist(
    W ~dnorm(mu,sigma),
    mu <- a+ba*A,
    a ~ dnorm(0,0.2),
    ba~dnorm(0,0.5),
    sigma ~dexp(1)
  ),
  data=foxes)

precis(m5)


compare(m1,m2,m3,m4,m5)
```